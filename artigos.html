<!DOCTYPEhtml>
<html lang="pt-BR">
<head>
	<title>Artigos</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css"  href="css/estilo.css" />
	<link rel="icon" href="Icones/caveira.ico" type="image/x-icon" />
	<link href='http://fonts.googleapis.com/css?family=Oswald' rel='stylesheet' type='text/css'>
</head>

<body>
	
<div id="cabecalho">
	<a href="index.html" class="imgAtiva"> <img src="Icones/DeepWebLogo.png"> </a>
</div>
	
<nav>
<div id="todoMenu">

<div id="linksMenu">
<ul>
  <li><a href="index.html">Home</a></li>
  <li><a href="intro.html">Introdução</a></li>   
  <li><a id="ativo" href="artigos.html">Artigos</a></li>   
  <li class="dropdown">
    <a href="#" class="dropbtn">Conteúdos</a>
    <div class="dropdown-content">
      <a href="oqeh.html">O que é</a>
      <a href="comosurgiu.html">Como surgiu</a>
      <a href="funcionabilidade.html">Como funciona</a>
      <a href="principaispages.html">Principais Páginas</a>
      <a href="riscovantagem.html">Riscos e Vantagens</a>
	  <a href="seguranca.html">Segurança</a>
	  <a href="transacoes.html">Transações</a>
    </div>
  </li>
  <li><a href="curiosidades.html">Curiosidades</a></li> 
</ul>
</div>

<div id="divBusca">
    <input type="text" id="txtBusca" placeholder="Buscar..."/>
    <img src="Icones/search.png" id="btnBusca" alt="Buscar"/>
</div>

</div>
</nav>
		
<div class="c1">
	<b>
		Diferentemente da web superfície, a web profunda é gerada dinamicamente a 
		partir de fontes de dados tais como: Banco de Dados ou Sistemas de Arquivos. 
		Segundo Q. Huang (2012, p. 5): 
	</b>
	<p>
		Ao contrário web superfície onde estão disponíveis através de URLs de 
		dados, dados de um web profunda são guardados por uma interface de 
		pesquisa. Isto exige crawlers profundas para escavar os dados para 
		que eles possam ser reutilizados, indexado e pesquisado em cima em 
		um ambiente integrado. Crawling Deep Web [2] é o processo de 
		recolha de dados ocultos através da emissão de consultas através de 
		várias interfaces de busca e armazenar os resultados em banco de 
		dados local, que incidem sobre o rastreamento de todo o banco de 
		dados web ao mesmo tempo.
	</p>
	<h4> Referência: </h4>	
		Q. Huang, Q. Li, H. Li et al. An approach to incremental deep web crawling based on 
		incremental harvest model. Circulação 2012. Vol 29. http://dx.doi.org/10.1016/j.proeng.2012.01.093
	<h4> Responsável: </h4>
					Rafael Danzer				
</div>	

<div class="c1">
	<b>
		A Deep Web tem uma vasta gama de conteúdo, e é necessário estruturar esses dados. 
		Segundo Q. Huang (2012, p. 7): 
	</b>
	<p>
		A quantidade de dados que se obtém na Deep Web é enorme. No entanto esses dados trazem 
		um significativo desperdício de tempo e espaço, já que é necessário rastrear as informações. 
		Por isso, esse problema é estudado, com uma abordagem eficiente e eficaz baseada em um 
		modelo de colheita, que é proposto para resolver este problema. 
		Os experimentos em três bases de dados reais da Web, mostra uma	abordagem que pode reduzir 
		significativamente o custo de indexação, sem a perda da taxa de cobertura periódica.
	</p>
	<h4> Referência: </h4>	
		Q. Huang, Q. Li, H. Li et al. An approach to incremental deep web crawling based on 
		incremental harvest model. Circulação 2012. Vol 29. http://dx.doi.org/10.1016/j.proeng.2012.01.093
	<h4> Responsável: </h4>
		Johny Klein 				
</div>				

<div class="c1">
	<b>
		Learning to crawl Deep Web 
	</b>
	<p>
		No Artigo , o autor diz que a Deep Web, se refere à proporção do WorldWideWeb, que não faz parte da superficie da web, o que está diretamente indexada pelos sites de busca. Vários estudos mostram que a Deep Web é particularmente valiosa. Não só o seu tamanho estimado, com centenas de vezes maior do que o da superficie da web, mas também fornece aos usuários informações de alta qualidade. No entanto, para obter dados a partir da Deep Web, é desafiador e tem sido reconhecida como uma lacuna significativa na cobertura de navegadores de busca. Há normalmente duas abordagens para acessar o conteúdo da web profunda: abordagem de integração virtual , database- centered e abordagem pavimentação ou '' crawl -and- index“. 
	</p>
	<h4> Referência: </h4>	
		Qinghua Zheng, Zhaohui Wu, Xiaocheng Cheng, Lu Jiang, Jun Liu, Learning to crawl deep web, Information Systems, Volume 38, Issue 6, September 2013, Pages 801-819, ISSN 0306-4379, http://dx.doi.org/10.1016/j.is.2013.02.001.
	<h4> Responsável: </h4>
		Henrique A. Rueckert 				
</div>	
	
<div id="rodape">
	<span id="textoRodape">Mídias Sociais:</span>
	</br>
	</br>
	<a href="https://www.facebook.com/" target="new_blank" class="imgAtiva"> <img src="Icones/facebook.png"> </a>
	<a href="https://www.instagram.com/" target="new_blank" class="imgAtiva"> <img src="Icones/instagram.png"> </a>
	<a href="https://www.youtube.com/?hl=pt&gl=BR" target="new_blank" class="imgAtiva"> <img src="Icones/youtube.png"> </a>
</div>
			
</body>	
</html>
